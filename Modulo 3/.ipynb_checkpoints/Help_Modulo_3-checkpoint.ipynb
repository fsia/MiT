{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Atividade do módulo 3: Classificação do MNIST**\n",
        "\n",
        "\n",
        "Agora que temos todo o poder do PyTorch à nossa disposição, podemos classificar um conjunto de dados mais concreto. Em particular, vamos construir um classificador para o conjunto de dados de dígitos manuscritos MNIST ([MNIST Handwritten Digits dataset](https://en.wikipedia.org/wiki/MNIST_database)). Este conjunto de dados contém dezenas de milhares de dígitos manuscritos de 0 a 9, sendo comumente usado para o desenvolvimento de algoritmos de aprendizagem de máquina. Nesta atividade, forneceremos um código básico de carregamento de dados para que você construa uma rede neural profunda treinada no conjunto de dados MNIST. Sinta-se à vontade para reutilizar o código que você escreveu ou viu em *notebooks* anteriores."
      ],
      "metadata": {
        "id": "1uCZ_UPrmRUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIIMjd6QmEz4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import time, copy\n",
        "\n",
        "# Configuração do dispositivo (treine nosso modelo na GPU, se disponível, pois é muito mais rápido)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiro, vamos carregar nosso conjunto de dados MNIST. O PyTorch fornece funções integradas para carregar conjuntos de dados de imagens populares, sendo o MNIST um deles."
      ],
      "metadata": {
        "id": "empWeSSeSGV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Essas transformações serão aplicadas em cada ponto de dados – neste exemplo, queremos transformar cada\n",
        "# ponto de dados em um tipo de dado Tensor\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
        "mnist_train = torchvision.datasets.MNIST('', train=True, transform =transform, download=True)\n",
        "# Vamos dividir o conjunto de dados de treinamento em treinamento e validação\n",
        "mnist_train, mnist_val = torch.utils.data.random_split(mnist_train, [50000, 10000])\n",
        "mnist_test = torchvision.datasets.MNIST('', train=False, transform = transform, download=True)\n"
      ],
      "metadata": {
        "id": "nIxOn6d_DowR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos criar os DataLoaders como antes, com um tamanho de lote de 100\n",
        "batch_size = 100\n",
        "dataloaders = {'train': DataLoader(mnist_train, batch_size=batch_size),\n",
        "               'val': DataLoader(mnist_val, batch_size=batch_size),\n",
        "               'test': DataLoader(mnist_test, batch_size=batch_size)}\n",
        "\n",
        "dataset_sizes = {'train': len(mnist_train),\n",
        "                 'val': len(mnist_val),\n",
        "                 'test': len(mnist_test)}\n",
        "print(f'dataset_sizes = {dataset_sizes}')"
      ],
      "metadata": {
        "id": "9X6r4BM4pdMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dica! No notebook \"Introdução ao PyTorch\", do módulo 3, a rede\n",
        "# que criamos requer que os dados de entrada tenham a forma Nx1, em que N é o número\n",
        "# de atributos. Atualmente, nosso conjunto de dados MNIST está na forma 28x28, pois são imagens. Use\n",
        "# este trecho de código enquanto itera pelos pontos de dados em seu conjunto de dados para nivelá-los,\n",
        "# para que tenham o tamanho 784x1 e possam ser usados com os modelos que projetamos anteriormente!\n",
        "\n",
        "# Este loop somente itera pelos pontos de dados \"train\"\n",
        "# No notebook anterior\n",
        "phases = [\"train\", \"val\", \"test\"]\n",
        "for phase in phases:\n",
        "  for inputs, labels in dataloaders[phase]:\n",
        "    # Isso nivela os lotes para o tamanho correto!\n",
        "    inputs = inputs.view(inputs.shape[0],-1)"
      ],
      "metadata": {
        "id": "u6tl7_VrwUU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INSERIR CÓDIGO AQUI\n",
        "\n",
        "# modelo =\n",
        "\n",
        "# perda e otimizador (\"loss and optimizer\") =\n",
        "# critério (\"criterion\") =\n",
        "# otimizador (\"optimizer\") =\n",
        "# agendador (\"scheduler\") =\n",
        "# Certifique-se de salvar as curvas de treinamento a medida que trabalha para visualização posterior\n",
        "# model, training_curves = train_model(...)"
      ],
      "metadata": {
        "id": "Bac-y0X2XymI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funções utilitárias para plotar seus resultados!\n",
        "def plot_training_curves(training_curves,\n",
        "                         phases=['train', 'val', 'test'],\n",
        "                         metrics=['loss','acc']):\n",
        "    epochs = list(range(len(training_curves['train_loss'])))\n",
        "    for metric in metrics:\n",
        "        plt.figure()\n",
        "        plt.title(f'Training curves - {metric}')\n",
        "        for phase in phases:\n",
        "            key = phase+'_'+metric\n",
        "            if key in training_curves:\n",
        "                plt.plot(epochs, training_curves[phase+'_'+metric])\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(labels=phases)\n",
        "\n",
        "def classify_predictions(model, device, dataloader):\n",
        "    model.eval()   # Definir o modelo no modo de avaliação\n",
        "    all_labels = torch.tensor([]).to(device)\n",
        "    all_scores = torch.tensor([]).to(device)\n",
        "    all_preds = torch.tensor([]).to(device)\n",
        "    for inputs, labels in dataloader:\n",
        "        # Importante! Precisamos nivelar cada ponto de dados\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = torch.softmax(model(inputs),dim=1)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        scores = outputs[:,1]\n",
        "        all_labels = torch.cat((all_labels, labels), 0)\n",
        "        all_scores = torch.cat((all_scores, scores), 0)\n",
        "        all_preds = torch.cat((all_preds, preds), 0)\n",
        "    return all_preds.detach().cpu(), all_labels.detach().cpu(), all_scores.detach().cpu()\n",
        "\n",
        "def plot_cm(model, device, dataloaders, phase='test'):\n",
        "    class_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "    preds, labels, scores = classify_predictions(model, device, dataloaders[phase])\n",
        "\n",
        "    cm = metrics.confusion_matrix(labels, preds)\n",
        "    disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "    ax = disp.plot().ax_\n",
        "    ax.set_title('Confusion Matrix -- counts')\n"
      ],
      "metadata": {
        "id": "58D0TK6DfFs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_curves(training_curves, phases=['train', 'val', 'test'])"
      ],
      "metadata": {
        "id": "I5afSrDnfMR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = plot_cm(model, device, dataloaders, phase='test')"
      ],
      "metadata": {
        "id": "zoi36p-jfPqL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}